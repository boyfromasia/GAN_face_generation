{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ohl-hxAAaNp"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running the correct version of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Y8_-1h5ddiDp",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a11c07cd-a3f3-4039-da0b-7a97b7a71560"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "Note: using Google CoLab\n",
      "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9LVr5sV8CKz0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2e8d585d-5731-49e7-b9e1-8e5634417a13"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'stylegan3'...\n",
      "remote: Enumerating objects: 212, done.\u001B[K\n",
      "remote: Counting objects: 100% (5/5), done.\u001B[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001B[K\n",
      "remote: Total 212 (delta 0), reused 1 (delta 0), pack-reused 207\u001B[K\n",
      "Receiving objects: 100% (212/212), 4.16 MiB | 19.83 MiB/s, done.\n",
      "Resolving deltas: 100% (101/101), done.\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting ninja\n",
      "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m146.0/146.0 kB\u001B[0m \u001B[31m3.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: ninja\n",
      "Successfully installed ninja-1.11.1\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVlabs/stylegan3.git\n",
    "!pip install ninja"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import the Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!gdown 1SPMnG0OJ9xgBdeTSgTkncyF2DCY0Jykm\n",
    "!unzip animefacedataset.zip"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D64Z7bfyqe6P",
    "outputId": "29515436-97be-4420-a63a-c2aedf2d6043"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1SPMnG0OJ9xgBdeTSgTkncyF2DCY0Jykm\n",
      "To: /content/animefacedataset.zip\n",
      "100% 414M/414M [00:11<00:00, 37.5MB/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBwmbfKJCORs"
   },
   "source": [
    "## Find Your Files\n",
    "\n",
    "The drive is mounted to the following location.\n",
    "\n",
    "```\n",
    "/content/drive/MyDrive/data\n",
    "```\n",
    "\n",
    "It might be helpful to use an ```ls``` command to establish the exact path for your images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rl6ShUWrCUrV"
   },
   "source": [
    "## Convert Your Images\n",
    "\n",
    "You must convert your images into a data set form that PyTorch can directly utilize. The following command converts your images and writes the resulting data set to another directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOK8m0N-Caqa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "47faf32c-79de-461c-e9ca-207233e100a3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100% 63565/63565 [06:51<00:00, 154.44it/s]\n"
     ]
    }
   ],
   "source": [
    "CMD = \"python /content/stylegan3/dataset_tool.py \"\\\n",
    "  \"--source /content/images \"\\\n",
    "  \"--dest /content/drive/MyDrive/AML/dataset/images\"\n",
    "\n",
    "!{CMD}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDbsiP35CdgK"
   },
   "source": [
    "You can use the following command to clear out the newly created dataset.  If something goes wrong and you need to clean up your images and rerun the above command, you should delete your partially completed dataset directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bpF072wiCgys",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c9aeaeba-e023-46e8-ee49-d7bdbe7751af"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "rm: cannot remove '/content/drive/MyDrive/AML/dataset/images/*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -R /content/drive/MyDrive/AML/dataset/images/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7sUkkb-CkrS"
   },
   "source": [
    "## Clean Up your Images\n",
    "\n",
    "All images must have the same dimensions and color depth.  This code can identify images that have issues."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "IMAGE_PATH = '/content/images'\n",
    "files = [f for f in listdir(IMAGE_PATH) if isfile(join(IMAGE_PATH, f))]\n",
    "\n",
    "base_size = None\n",
    "for file in tqdm(files):\n",
    "  file2 = os.path.join(IMAGE_PATH,file)\n",
    "  img = Image.open(file2)\n",
    "  new_image = img.resize((64, 64))\n",
    "  new_image.save(file2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "079cfceade2d453bbb3ca52408b38001",
      "9c89b5f9321e4f829649a12fc4cd5b29",
      "dff45ac57e5f49fbbeb69f8a599b31b8",
      "36670a70c51249859d33811720462878",
      "5146b051b0f0428da184c059a35b7ce9",
      "9cb92814688d4cfe9c5edab6e80318dc",
      "c09c703f8585423887663842b92203ba",
      "94c8f7909c204125bbfd8c6e2be2a6be",
      "dfc0002132034b04afc8b7c08771c75f",
      "1a449919defc4f31933159a6fbe21a7c",
      "110365b89f544816b77c892aaaf091e1"
     ]
    },
    "id": "0n7GVh7rrgOu",
    "outputId": "12dd1d62-ff9d-435d-ca29-2d6676dcf772"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/63565 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "079cfceade2d453bbb3ca52408b38001"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuWfEfEoColz",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "238247fdbba945cda6e41eaca56d1260",
      "b5df8cb0d3a54c019cdb3cf3ea77b7f0",
      "35facf594eb141c5824341a2ee0da1ac",
      "5c80a10ef7b64ee8904c0b8b1b64927a",
      "0ce2e1e23123432bae2f503bb14f23df",
      "18f39a2d42104351b44ad48879b871f9",
      "6db17da0a591431089e305bd8beec5d2",
      "c03313bcd1ed4077adaed338adb889d1",
      "bc916e1f673a456f9f3b61783a20795a",
      "6fd5ecfe3e4a41809fc0e0b4d167a406",
      "2de5978b031541a8b2aaab6ec2f506e6"
     ]
    },
    "outputId": "f7eeac35-c7ee-4279-9c5f-bdc81ddb65bb"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/63565 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "238247fdbba945cda6e41eaca56d1260"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "IMAGE_PATH = '/content/images'\n",
    "files = [f for f in listdir(IMAGE_PATH) if isfile(join(IMAGE_PATH, f))]\n",
    "\n",
    "base_size = None\n",
    "for file in tqdm(files):\n",
    "  file2 = os.path.join(IMAGE_PATH,file)\n",
    "  img = Image.open(file2)\n",
    "  sz = img.size\n",
    "  if base_size and sz != base_size:\n",
    "    print(f\"Inconsistant size: {file2}\")\n",
    "  elif img.mode!='RGB':\n",
    "    print(f\"Inconsistant color format: {file2}\")\n",
    "  else:\n",
    "    base_size = sz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HyFZgnjCsPb"
   },
   "source": [
    "## Perform Initial Training\n",
    "\n",
    "This code performs the initial training.  Set SNAP low enough to get a snapshot before Colab forces you to quit."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!python /content/stylegan3/train.py --help"
   ],
   "metadata": {
    "id": "e6WE1cMk_5DM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-ZBcql7Cv14",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2f310945-1127-4e1a-d1cb-2ff9e249226b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_kwargs\": {\n",
      "    \"class_name\": \"training.networks_stylegan2.Generator\",\n",
      "    \"z_dim\": 512,\n",
      "    \"w_dim\": 512,\n",
      "    \"mapping_kwargs\": {\n",
      "      \"num_layers\": 8\n",
      "    },\n",
      "    \"channel_base\": 32768,\n",
      "    \"channel_max\": 512,\n",
      "    \"fused_modconv_default\": \"inference_only\"\n",
      "  },\n",
      "  \"D_kwargs\": {\n",
      "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
      "    \"block_kwargs\": {\n",
      "      \"freeze_layers\": 0\n",
      "    },\n",
      "    \"mapping_kwargs\": {},\n",
      "    \"epilogue_kwargs\": {\n",
      "      \"mbstd_group_size\": 4\n",
      "    },\n",
      "    \"channel_base\": 32768,\n",
      "    \"channel_max\": 512\n",
      "  },\n",
      "  \"G_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08,\n",
      "    \"lr\": 0.002\n",
      "  },\n",
      "  \"D_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08,\n",
      "    \"lr\": 0.002\n",
      "  },\n",
      "  \"loss_kwargs\": {\n",
      "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
      "    \"r1_gamma\": 10.0,\n",
      "    \"style_mixing_prob\": 0.9,\n",
      "    \"pl_weight\": 2,\n",
      "    \"pl_no_weight_grad\": true\n",
      "  },\n",
      "  \"data_loader_kwargs\": {\n",
      "    \"pin_memory\": true,\n",
      "    \"prefetch_factor\": 2,\n",
      "    \"num_workers\": 3\n",
      "  },\n",
      "  \"training_set_kwargs\": {\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "    \"path\": \"/content/drive/MyDrive/AML/dataset/images\",\n",
      "    \"use_labels\": false,\n",
      "    \"max_size\": 11674,\n",
      "    \"xflip\": false,\n",
      "    \"resolution\": 64,\n",
      "    \"random_seed\": 0\n",
      "  },\n",
      "  \"num_gpus\": 1,\n",
      "  \"batch_size\": 32,\n",
      "  \"batch_gpu\": 32,\n",
      "  \"metrics\": [\n",
      "    \"fid50k_full\"\n",
      "  ],\n",
      "  \"total_kimg\": 25000,\n",
      "  \"kimg_per_tick\": 4,\n",
      "  \"image_snapshot_ticks\": 10,\n",
      "  \"network_snapshot_ticks\": 10,\n",
      "  \"random_seed\": 0,\n",
      "  \"ema_kimg\": 10.0,\n",
      "  \"G_reg_interval\": 4,\n",
      "  \"augment_kwargs\": {\n",
      "    \"class_name\": \"training.augment.AugmentPipe\",\n",
      "    \"xflip\": 1,\n",
      "    \"rotate90\": 1,\n",
      "    \"xint\": 1,\n",
      "    \"scale\": 1,\n",
      "    \"rotate\": 1,\n",
      "    \"aniso\": 1,\n",
      "    \"xfrac\": 1,\n",
      "    \"brightness\": 1,\n",
      "    \"contrast\": 1,\n",
      "    \"lumaflip\": 1,\n",
      "    \"hue\": 1,\n",
      "    \"saturation\": 1\n",
      "  },\n",
      "  \"ada_target\": 0.6,\n",
      "  \"run_dir\": \"/content/drive/MyDrive/AML/experiments/00002-stylegan2-images-gpus1-batch32-gamma10\"\n",
      "}\n",
      "\n",
      "Output directory:    /content/drive/MyDrive/AML/experiments/00002-stylegan2-images-gpus1-batch32-gamma10\n",
      "Number of GPUs:      1\n",
      "Batch size:          32 images\n",
      "Training duration:   25000 kimg\n",
      "Dataset path:        /content/drive/MyDrive/AML/dataset/images\n",
      "Dataset size:        11674 images\n",
      "Dataset resolution:  64\n",
      "Dataset labels:      False\n",
      "Dataset x-flips:     False\n",
      "\n",
      "Creating output directory...\n",
      "Launching processes...\n",
      "Loading training set...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\n",
      "Num images:  11674\n",
      "Image shape: [3, 64, 64]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "\n",
      "Generator            Parameters  Buffers  Output shape       Datatype\n",
      "---                  ---         ---      ---                ---     \n",
      "mapping.fc0          262656      -        [32, 512]          float32 \n",
      "mapping.fc1          262656      -        [32, 512]          float32 \n",
      "mapping.fc2          262656      -        [32, 512]          float32 \n",
      "mapping.fc3          262656      -        [32, 512]          float32 \n",
      "mapping.fc4          262656      -        [32, 512]          float32 \n",
      "mapping.fc5          262656      -        [32, 512]          float32 \n",
      "mapping.fc6          262656      -        [32, 512]          float32 \n",
      "mapping.fc7          262656      -        [32, 512]          float32 \n",
      "mapping              -           512      [32, 10, 512]      float32 \n",
      "synthesis.b4.conv1   2622465     32       [32, 512, 4, 4]    float32 \n",
      "synthesis.b4.torgb   264195      -        [32, 3, 4, 4]      float32 \n",
      "synthesis.b4:0       8192        16       [32, 512, 4, 4]    float32 \n",
      "synthesis.b4:1       -           -        [32, 3, 4, 4]      float32 \n",
      "synthesis.b8.conv0   2622465     80       [32, 512, 8, 8]    float16 \n",
      "synthesis.b8.conv1   2622465     80       [32, 512, 8, 8]    float16 \n",
      "synthesis.b8.torgb   264195      -        [32, 3, 8, 8]      float16 \n",
      "synthesis.b8:0       -           16       [32, 512, 8, 8]    float16 \n",
      "synthesis.b8:1       -           -        [32, 3, 8, 8]      float32 \n",
      "synthesis.b16.conv0  2622465     272      [32, 512, 16, 16]  float16 \n",
      "synthesis.b16.conv1  2622465     272      [32, 512, 16, 16]  float16 \n",
      "synthesis.b16.torgb  264195      -        [32, 3, 16, 16]    float16 \n",
      "synthesis.b16:0      -           16       [32, 512, 16, 16]  float16 \n",
      "synthesis.b16:1      -           -        [32, 3, 16, 16]    float32 \n",
      "synthesis.b32.conv0  2622465     1040     [32, 512, 32, 32]  float16 \n",
      "synthesis.b32.conv1  2622465     1040     [32, 512, 32, 32]  float16 \n",
      "synthesis.b32.torgb  264195      -        [32, 3, 32, 32]    float16 \n",
      "synthesis.b32:0      -           16       [32, 512, 32, 32]  float16 \n",
      "synthesis.b32:1      -           -        [32, 3, 32, 32]    float32 \n",
      "synthesis.b64.conv0  2622465     4112     [32, 512, 64, 64]  float16 \n",
      "synthesis.b64.conv1  2622465     4112     [32, 512, 64, 64]  float16 \n",
      "synthesis.b64.torgb  264195      -        [32, 3, 64, 64]    float16 \n",
      "synthesis.b64:0      -           16       [32, 512, 64, 64]  float16 \n",
      "synthesis.b64:1      -           -        [32, 3, 64, 64]    float32 \n",
      "---                  ---         ---      ---                ---     \n",
      "Total                27032600    11632    -                  -       \n",
      "\n",
      "\n",
      "Discriminator  Parameters  Buffers  Output shape       Datatype\n",
      "---            ---         ---      ---                ---     \n",
      "b64.fromrgb    2048        16       [32, 512, 64, 64]  float16 \n",
      "b64.skip       262144      16       [32, 512, 32, 32]  float16 \n",
      "b64.conv0      2359808     16       [32, 512, 64, 64]  float16 \n",
      "b64.conv1      2359808     16       [32, 512, 32, 32]  float16 \n",
      "b64            -           16       [32, 512, 32, 32]  float16 \n",
      "b32.skip       262144      16       [32, 512, 16, 16]  float16 \n",
      "b32.conv0      2359808     16       [32, 512, 32, 32]  float16 \n",
      "b32.conv1      2359808     16       [32, 512, 16, 16]  float16 \n",
      "b32            -           16       [32, 512, 16, 16]  float16 \n",
      "b16.skip       262144      16       [32, 512, 8, 8]    float16 \n",
      "b16.conv0      2359808     16       [32, 512, 16, 16]  float16 \n",
      "b16.conv1      2359808     16       [32, 512, 8, 8]    float16 \n",
      "b16            -           16       [32, 512, 8, 8]    float16 \n",
      "b8.skip        262144      16       [32, 512, 4, 4]    float16 \n",
      "b8.conv0       2359808     16       [32, 512, 8, 8]    float16 \n",
      "b8.conv1       2359808     16       [32, 512, 4, 4]    float16 \n",
      "b8             -           16       [32, 512, 4, 4]    float16 \n",
      "b4.mbstd       -           -        [32, 513, 4, 4]    float32 \n",
      "b4.conv        2364416     16       [32, 512, 4, 4]    float32 \n",
      "b4.fc          4194816     -        [32, 512]          float32 \n",
      "b4.out         513         -        [32, 1]            float32 \n",
      "---            ---         ---      ---                ---     \n",
      "Total          26488833    288      -                  -       \n",
      "\n",
      "Setting up augmentation...\n",
      "Distributing across 1 GPUs...\n",
      "Setting up training phases...\n",
      "Exporting sample images...\n",
      "Initializing logs...\n",
      "2023-05-04 18:44:46.910458: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-04 18:44:48.120084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Training for 25000 kimg...\n",
      "\n",
      "tick 0     kimg 0.0      time 7m 43s       sec/tick 14.9    sec/kimg 465.40  maintenance 448.0  cpumem 4.50   gpumem 11.36  reserved 12.72  augment 0.000\n",
      "Evaluating metrics...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "{\"results\": {\"fid50k_full\": 270.46233905890256}, \"metric\": \"fid50k_full\", \"total_time\": 1854.635605096817, \"total_time_str\": \"30m 55s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1683227768.5689}\n",
      "tick 1     kimg 4.0      time 41m 29s      sec/tick 161.5   sec/kimg 40.37   maintenance 1864.4 cpumem 4.94   gpumem 10.30  reserved 10.45  augment 0.005\n",
      "tick 2     kimg 8.0      time 44m 12s      sec/tick 162.6   sec/kimg 40.65   maintenance 0.2    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.008\n",
      "tick 3     kimg 12.0     time 46m 55s      sec/tick 163.1   sec/kimg 40.78   maintenance 0.2    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.009\n",
      "tick 4     kimg 16.0     time 49m 38s      sec/tick 163.5   sec/kimg 40.87   maintenance 0.0    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.012\n",
      "tick 5     kimg 20.0     time 52m 22s      sec/tick 163.1   sec/kimg 40.78   maintenance 0.2    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.012\n",
      "tick 6     kimg 24.0     time 55m 04s      sec/tick 162.6   sec/kimg 40.64   maintenance 0.2    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.010\n",
      "tick 7     kimg 28.0     time 57m 48s      sec/tick 163.2   sec/kimg 40.80   maintenance 0.2    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.008\n",
      "tick 8     kimg 32.0     time 1h 00m 31s   sec/tick 163.4   sec/kimg 40.86   maintenance 0.0    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.005\n",
      "tick 9     kimg 36.0     time 1h 03m 14s   sec/tick 163.0   sec/kimg 40.74   maintenance 0.2    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 10    kimg 40.0     time 1h 05m 58s   sec/tick 162.9   sec/kimg 40.74   maintenance 0.2    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 258.32686013138914}, \"metric\": \"fid50k_full\", \"total_time\": 597.4212961196899, \"total_time_str\": \"9m 57s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000040.pkl\", \"timestamp\": 1683230006.125004}\n",
      "tick 11    kimg 44.0     time 1h 18m 47s   sec/tick 162.0   sec/kimg 40.50   maintenance 607.3  cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 12    kimg 48.0     time 1h 21m 30s   sec/tick 163.5   sec/kimg 40.87   maintenance 0.0    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 13    kimg 52.0     time 1h 24m 14s   sec/tick 163.0   sec/kimg 40.75   maintenance 0.2    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.001\n",
      "tick 14    kimg 56.0     time 1h 26m 57s   sec/tick 163.2   sec/kimg 40.79   maintenance 0.2    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 15    kimg 60.0     time 1h 29m 41s   sec/tick 163.4   sec/kimg 40.86   maintenance 0.2    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 16    kimg 64.0     time 1h 32m 24s   sec/tick 163.4   sec/kimg 40.86   maintenance 0.0    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 17    kimg 68.0     time 1h 35m 07s   sec/tick 162.7   sec/kimg 40.69   maintenance 0.4    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 18    kimg 72.0     time 1h 37m 51s   sec/tick 163.2   sec/kimg 40.81   maintenance 0.2    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 19    kimg 76.0     time 1h 40m 34s   sec/tick 163.2   sec/kimg 40.79   maintenance 0.2    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 20    kimg 80.0     time 1h 43m 18s   sec/tick 164.0   sec/kimg 41.00   maintenance 0.0    cpumem 4.94   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 103.25550650732717}, \"metric\": \"fid50k_full\", \"total_time\": 601.8711416721344, \"total_time_str\": \"10m 02s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000080.pkl\", \"timestamp\": 1683232250.8498878}\n",
      "tick 21    kimg 84.0     time 1h 56m 12s   sec/tick 162.4   sec/kimg 40.60   maintenance 611.7  cpumem 4.92   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 22    kimg 88.0     time 1h 58m 55s   sec/tick 162.8   sec/kimg 40.70   maintenance 0.2    cpumem 4.92   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 23    kimg 92.0     time 2h 01m 39s   sec/tick 163.6   sec/kimg 40.89   maintenance 0.2    cpumem 4.92   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 24    kimg 96.0     time 2h 04m 22s   sec/tick 163.6   sec/kimg 40.89   maintenance 0.0    cpumem 4.92   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 25    kimg 100.0    time 2h 07m 06s   sec/tick 163.2   sec/kimg 40.81   maintenance 0.2    cpumem 4.92   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 26    kimg 104.0    time 2h 09m 49s   sec/tick 163.2   sec/kimg 40.79   maintenance 0.2    cpumem 4.92   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 27    kimg 108.0    time 2h 12m 32s   sec/tick 162.8   sec/kimg 40.69   maintenance 0.2    cpumem 4.92   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 28    kimg 112.0    time 2h 15m 16s   sec/tick 163.7   sec/kimg 40.93   maintenance 0.0    cpumem 4.92   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 29    kimg 116.0    time 2h 17m 59s   sec/tick 163.2   sec/kimg 40.79   maintenance 0.2    cpumem 4.92   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 30    kimg 120.0    time 2h 20m 43s   sec/tick 163.2   sec/kimg 40.80   maintenance 0.2    cpumem 4.92   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 60.794849000203115}, \"metric\": \"fid50k_full\", \"total_time\": 601.844288110733, \"total_time_str\": \"10m 02s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000120.pkl\", \"timestamp\": 1683234495.0771325}\n",
      "tick 31    kimg 124.0    time 2h 33m 38s   sec/tick 164.0   sec/kimg 41.00   maintenance 611.3  cpumem 4.90   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 32    kimg 128.0    time 2h 36m 21s   sec/tick 163.5   sec/kimg 40.86   maintenance 0.0    cpumem 4.90   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 33    kimg 132.0    time 2h 39m 05s   sec/tick 162.9   sec/kimg 40.72   maintenance 0.4    cpumem 4.90   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 34    kimg 136.0    time 2h 41m 48s   sec/tick 163.4   sec/kimg 40.84   maintenance 0.2    cpumem 4.90   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 35    kimg 140.0    time 2h 44m 32s   sec/tick 163.6   sec/kimg 40.90   maintenance 0.2    cpumem 4.90   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 36    kimg 144.0    time 2h 47m 16s   sec/tick 163.7   sec/kimg 40.93   maintenance 0.0    cpumem 4.90   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 37    kimg 148.0    time 2h 49m 59s   sec/tick 163.2   sec/kimg 40.80   maintenance 0.2    cpumem 4.90   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 38    kimg 152.0    time 2h 52m 42s   sec/tick 162.7   sec/kimg 40.68   maintenance 0.2    cpumem 4.90   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 39    kimg 156.0    time 2h 55m 25s   sec/tick 163.4   sec/kimg 40.84   maintenance 0.2    cpumem 4.90   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 40    kimg 160.0    time 2h 58m 09s   sec/tick 163.9   sec/kimg 40.98   maintenance 0.0    cpumem 4.90   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 45.74336220334397}, \"metric\": \"fid50k_full\", \"total_time\": 608.6274597644806, \"total_time_str\": \"10m 09s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000160.pkl\", \"timestamp\": 1683236749.3883593}\n",
      "tick 41    kimg 164.0    time 3h 11m 11s   sec/tick 162.6   sec/kimg 40.64   maintenance 618.7  cpumem 4.88   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 42    kimg 168.0    time 3h 13m 54s   sec/tick 163.2   sec/kimg 40.81   maintenance 0.2    cpumem 4.88   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 43    kimg 172.0    time 3h 16m 37s   sec/tick 163.0   sec/kimg 40.76   maintenance 0.2    cpumem 4.88   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 44    kimg 176.0    time 3h 19m 21s   sec/tick 163.9   sec/kimg 40.97   maintenance 0.0    cpumem 4.88   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 45    kimg 180.0    time 3h 22m 05s   sec/tick 163.5   sec/kimg 40.88   maintenance 0.2    cpumem 4.88   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 46    kimg 184.0    time 3h 24m 48s   sec/tick 163.3   sec/kimg 40.84   maintenance 0.2    cpumem 4.88   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 47    kimg 188.0    time 3h 27m 32s   sec/tick 163.4   sec/kimg 40.85   maintenance 0.2    cpumem 4.88   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 48    kimg 192.0    time 3h 30m 16s   sec/tick 163.6   sec/kimg 40.91   maintenance 0.0    cpumem 4.88   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 49    kimg 196.0    time 3h 32m 59s   sec/tick 162.8   sec/kimg 40.70   maintenance 0.4    cpumem 4.88   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 50    kimg 200.0    time 3h 35m 42s   sec/tick 163.1   sec/kimg 40.78   maintenance 0.2    cpumem 4.88   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 38.087293626735345}, \"metric\": \"fid50k_full\", \"total_time\": 597.8242897987366, \"total_time_str\": \"9m 58s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000200.pkl\", \"timestamp\": 1683238991.2933097}\n",
      "tick 51    kimg 204.0    time 3h 48m 33s   sec/tick 163.5   sec/kimg 40.87   maintenance 607.8  cpumem 4.78   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 52    kimg 208.0    time 3h 51m 17s   sec/tick 163.4   sec/kimg 40.86   maintenance 0.0    cpumem 4.78   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 53    kimg 212.0    time 3h 54m 00s   sec/tick 162.9   sec/kimg 40.72   maintenance 0.2    cpumem 4.78   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 54    kimg 216.0    time 3h 56m 43s   sec/tick 162.4   sec/kimg 40.60   maintenance 0.2    cpumem 4.78   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 55    kimg 220.0    time 3h 59m 26s   sec/tick 163.1   sec/kimg 40.78   maintenance 0.2    cpumem 4.78   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 56    kimg 224.0    time 4h 02m 09s   sec/tick 163.5   sec/kimg 40.88   maintenance 0.0    cpumem 4.78   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 57    kimg 228.0    time 4h 04m 53s   sec/tick 163.0   sec/kimg 40.74   maintenance 0.2    cpumem 4.78   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 58    kimg 232.0    time 4h 07m 36s   sec/tick 162.9   sec/kimg 40.73   maintenance 0.2    cpumem 4.78   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 59    kimg 236.0    time 4h 10m 19s   sec/tick 162.9   sec/kimg 40.71   maintenance 0.2    cpumem 4.78   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "tick 60    kimg 240.0    time 4h 13m 02s   sec/tick 163.5   sec/kimg 40.87   maintenance 0.0    cpumem 4.78   gpumem 6.44   reserved 6.80   augment 0.000\n",
      "Evaluating metrics...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Modify these to suit your needs\n",
    "EXPERIMENTS = \"/content/drive/MyDrive/AML/experiments\"\n",
    "DATA = \"/content/drive/MyDrive/AML/dataset/images\"\n",
    "SNAP = 10\n",
    "\n",
    "cmd = f\"/usr/bin/python3 /content/stylegan3/train.py \"\\\n",
    "  f\"--snap {SNAP} --outdir {EXPERIMENTS} --data {DATA} --gpus=1 --batch=32 --gamma=10 --cfg=stylegan2\"\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhOQRZrJDCvA"
   },
   "source": [
    "## Resume Training\n",
    "\n",
    "You can now resume training after you are interrupted by something in the pervious step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1TFgr9MDJlS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Modify these to suit your needs\n",
    "EXPERIMENTS = \"/content/drive/MyDrive/data/gan/experiments\"\n",
    "NETWORK = \"network-snapshot-000100.pkl\"\n",
    "RESUME = os.path.join(EXPERIMENTS, \\\n",
    "                \"00008-circuit-auto1-resumecustom\", NETWORK)\n",
    "DATA = \"/content/drive/MyDrive/data/gan/dataset/circuit\"\n",
    "SNAP = 10\n",
    "\n",
    "# Build the command and run it\n",
    "cmd = f\"/usr/bin/python3 /content/stylegan3/train.py \"\\\n",
    "  f\"--snap {SNAP} --resume {RESUME} --outdir {EXPERIMENTS} --data {DATA}\"\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "5TVTEBmFNCFg"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "079cfceade2d453bbb3ca52408b38001": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9c89b5f9321e4f829649a12fc4cd5b29",
       "IPY_MODEL_dff45ac57e5f49fbbeb69f8a599b31b8",
       "IPY_MODEL_36670a70c51249859d33811720462878"
      ],
      "layout": "IPY_MODEL_5146b051b0f0428da184c059a35b7ce9"
     }
    },
    "9c89b5f9321e4f829649a12fc4cd5b29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cb92814688d4cfe9c5edab6e80318dc",
      "placeholder": "​",
      "style": "IPY_MODEL_c09c703f8585423887663842b92203ba",
      "value": "100%"
     }
    },
    "dff45ac57e5f49fbbeb69f8a599b31b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94c8f7909c204125bbfd8c6e2be2a6be",
      "max": 63565,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dfc0002132034b04afc8b7c08771c75f",
      "value": 63565
     }
    },
    "36670a70c51249859d33811720462878": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a449919defc4f31933159a6fbe21a7c",
      "placeholder": "​",
      "style": "IPY_MODEL_110365b89f544816b77c892aaaf091e1",
      "value": " 63565/63565 [01:01&lt;00:00, 1139.79it/s]"
     }
    },
    "5146b051b0f0428da184c059a35b7ce9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cb92814688d4cfe9c5edab6e80318dc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c09c703f8585423887663842b92203ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "94c8f7909c204125bbfd8c6e2be2a6be": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfc0002132034b04afc8b7c08771c75f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a449919defc4f31933159a6fbe21a7c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "110365b89f544816b77c892aaaf091e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "238247fdbba945cda6e41eaca56d1260": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b5df8cb0d3a54c019cdb3cf3ea77b7f0",
       "IPY_MODEL_35facf594eb141c5824341a2ee0da1ac",
       "IPY_MODEL_5c80a10ef7b64ee8904c0b8b1b64927a"
      ],
      "layout": "IPY_MODEL_0ce2e1e23123432bae2f503bb14f23df"
     }
    },
    "b5df8cb0d3a54c019cdb3cf3ea77b7f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18f39a2d42104351b44ad48879b871f9",
      "placeholder": "​",
      "style": "IPY_MODEL_6db17da0a591431089e305bd8beec5d2",
      "value": "100%"
     }
    },
    "35facf594eb141c5824341a2ee0da1ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c03313bcd1ed4077adaed338adb889d1",
      "max": 63565,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bc916e1f673a456f9f3b61783a20795a",
      "value": 63565
     }
    },
    "5c80a10ef7b64ee8904c0b8b1b64927a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fd5ecfe3e4a41809fc0e0b4d167a406",
      "placeholder": "​",
      "style": "IPY_MODEL_2de5978b031541a8b2aaab6ec2f506e6",
      "value": " 63565/63565 [00:04&lt;00:00, 13474.23it/s]"
     }
    },
    "0ce2e1e23123432bae2f503bb14f23df": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18f39a2d42104351b44ad48879b871f9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6db17da0a591431089e305bd8beec5d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c03313bcd1ed4077adaed338adb889d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc916e1f673a456f9f3b61783a20795a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6fd5ecfe3e4a41809fc0e0b4d167a406": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2de5978b031541a8b2aaab6ec2f506e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
